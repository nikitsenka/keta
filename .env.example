# KETA Environment Configuration

# Database
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/keta_db

# LLM Provider Configuration
# Options: local, azure, openai
LLM_PROVIDER=local

# Common LLM Settings
MODEL_TEMPERATURE=0.0
MODEL_MAX_RETRIES=5
MODEL_TIMEOUT=120

# Azure Mistral (Production)
# AZURE_MISTRAL_ENDPOINT=https://your-endpoint.region.inference.ai.azure.com
# AZURE_MISTRAL_API_KEY=your_azure_api_key_here
# MISTRAL_MODEL=mistral-large-latest

# Local Ollama (Development)
OLLAMA_BASE_URL=http://ollama:11434
OLLAMA_MODEL=mistral

# OpenAI API (Optional Fallback)
# OPENAI_API_KEY=your_openai_api_key_here
# OPENAI_MODEL=gpt-4o-mini

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
LOG_LEVEL=INFO

# UI Configuration
VITE_API_URL=http://localhost:8000
